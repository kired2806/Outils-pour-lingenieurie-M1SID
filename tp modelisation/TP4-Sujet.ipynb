{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4: Regression logistique (pédestre)\n",
    "\n",
    "En fin de séance, votre TP devra être déposé sur le dépot:\n",
    "https://synapse.math.univ-toulouse.fr/s/X4l9EeymOIEpfOm\n",
    "\n",
    "**Attention: Je n'accepte pas les TPs d'élèves absents en cours.**\n",
    "\n",
    "Nous nous intéressons au dataset public [Framingham](https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset)\n",
    "issu d'une étude en 1948 à Framingham, Massaschussets, USA et coordonnée par le U.S. Public Health Service. Je vous propose la version [ici](https://www.math.univ-toulouse.fr/~rchhaibi/teaching/2019/M1SID/framingham_fr.csv)\n",
    "où j'ai simplement traduit les champs. Vous pouvez consultez les kernels disponibles, mais le but de ce TP est une implémentation plus manuelle et pédestre de la régression linéaire.\n",
    "\n",
    "Description par le gouvernement américain: [Lien](https://biolincc.nhlbi.nih.gov/studies/framcohort/)\n",
    "- Pour les variables binaires : “1”=“Oui”, “0”=“Non”.\n",
    "- Pour les variables continues: Valeur intensive\n",
    "\n",
    "Variable d'intérêt en dernière colonne:\n",
    "Risque à 10 ans de développer une maladie coronaire (binaire)\n",
    "\n",
    "* Facteurs démographiques:\n",
    "  * Sexe: Masculin ou Feminin (binaire: \"1\"=Masculin)\n",
    "  * Age: Continu\n",
    "  * Education: Niveau d'éducation 1,2,3,4\n",
    "* Facteurs comportementaux:\n",
    "  * Fumeur: (binaire)\n",
    "  * CigsParJour: Cigarette par jour\n",
    "* Facteurs médicaux historiques / Historique médical:\n",
    "  * meds (binaire): si le patient est traité pour des problèmes de pression sanguine\n",
    "  * avc  (binaire): si le patient a déjà fait un avc\n",
    "  * hypertension (binaire): si le patient a de l'hypertension\n",
    "  * diabete (binaire): si le patient est diabétique\n",
    "* Facteurs médicaux courants:\n",
    "  * Tot Chol: niveau de cholesterol total HDL + LDL + VLDL (Continu)\n",
    "  * Sys BP: pression sanguine systolique (Continu)\n",
    "  * Dia BP: pression sanguine diastolique (Continu)\n",
    "  * IMC: Indice de Masse Corporelle (Continu)\n",
    "  * freqCardique: Fréquence cardiaque (Continu)\n",
    "  * Glucose: niveau de glucose (Continu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Echauffement: L'algorithme de Newton-Raphson\n",
    "\n",
    "Exercice 1:\n",
    "- Rappeler la récurrence de Newton-Raphson vue en cours, dans sa version scalaire\n",
    "- Implémenter l'algorithme de Newton-Raphson, toujours dans sa version scalaire\n",
    "- Commenter la vitesse de convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version scalaire\n",
    "def newton_raphson_scalar( x0, func, grad_func, n_max=100, eps=1e-8):\n",
    "    x = x0 # TODO: Value\n",
    "    k = 0  # TODO: Number of steps\n",
    "    return (x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pour la version scalaire\n",
    "a    = 2\n",
    "scalar_func = lambda x: x**2-a\n",
    "scalar_grad = lambda x: 2*x\n",
    "\n",
    "count  = 8\n",
    "errors = []\n",
    "print(\"Target value: \", np.sqrt(a))\n",
    "print(\"NR value / Iteration count:\")\n",
    "for n_max in range(1,count):\n",
    "    x, k = newton_raphson_scalar(1, scalar_func, scalar_grad, n_max=n_max)\n",
    "    print(x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Exploration de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2:\n",
    "- Lire le code suivant.\n",
    "- Pourquoi elève-t-on la colonne \"education\"? Il s'agit pourtant (sans doute) d'un facteur pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Importation des données et nettoyage\n",
    "dataframe=pd.read_csv(\"framingham_fr.csv\")\n",
    "dataframe.drop(['education'],axis=1,inplace=True)\n",
    "dataframe.head()\n",
    "\n",
    "#Counting the missing values and dropping them\n",
    "count=0\n",
    "for i in dataframe.isnull().sum(axis=1):\n",
    "    if i>0:\n",
    "        count=count+1\n",
    "print(\"Le nombre total de lignes avec des valeurs manquantes est \", count)\n",
    "print(\"Il s'agit de\",round((count/len(dataframe.index))*100), '% du jeu de données.')\n",
    "print(\"\")\n",
    "dataframe.dropna(axis=0,inplace=True)\n",
    "\n",
    "#Ajout de la constante\n",
    "from statsmodels.tools import add_constant as add_constant\n",
    "dataframe = add_constant(dataframe)\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"Statistiques descriptives:\")\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dataframe.columns\n",
    "# Définition de la variable d'intéret\n",
    "Y = np.array( dataframe[cols[-1]] )\n",
    "# Définition de la matrice des facteurs\n",
    "X = np.array( dataframe[cols[:-1]] )\n",
    "# Taille des matrices\n",
    "print(\"dim X: \", X.shape)\n",
    "print(\"dim Y: \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Implémentation de la régression logistique\n",
    "\n",
    "Nous nous intéressons à l'estimation de \n",
    "$$ \\mathbb{P}\\left( Y=1 | X \\right)$$\n",
    "grâce à un modèle de régression logistique. On pourra se référer à la [page Wikipedia](https://fr.wikipedia.org/wiki/R%C3%A9gression_logistique#Le_mod%C3%A8le).\n",
    "\n",
    "- La fonction de lien est définie pour $p = \\mathbb{P}\\left( Y = 1 | X \\right) = \\mathbb{E}\\left( Y | X \\right)$ par\n",
    "$$ \n",
    "   \\textrm{logit}( p )\n",
    " = \\log\\left( \\frac{p}{1-p} \\right)\n",
    " = \\beta X \\ ,\n",
    "$$\n",
    "où $\\beta X$ est le produit scalaire entre les paramètres $\\beta \\in \\mathbb{R}^k$ et les facteurs $X \\in \\mathbb{R}^k$. De façon équivalente:\n",
    "$$ p = \\frac{e^{\\beta X}}{1+e^{\\beta X}} \\ .$$\n",
    "\n",
    "- Dans ce cas, la log-vraisemblance s'écrit\n",
    "$$\n",
    "   \\ell\\left( y, x, \\beta \\right)\n",
    " = \\frac{1}{n} \\sum_{i=1}^n \\left[\n",
    "   y_i \\left( \\beta x_i \\right)\n",
    "   - \\log (1+e^{\\beta x_i})\n",
    "   \\right]\n",
    "$$\n",
    "Preuve:\n",
    "$$\n",
    "   \\begin{align*}\n",
    "   \\ell\\left( y, x, \\beta \\right) := & \\frac{1}{n} \\log \\mathbb{P}\\left( \\forall i, \\ Y_i = y_i | \\forall i, \\ X_i = x_i \\right) \\\\\n",
    "   = & \\frac{1}{n} \\sum_{i=1}^n \\log \\mathbb{P}\\left( Y_i = y_i | X_i = x_i \\right) \\\\\n",
    "   = & \\frac{1}{n} \\sum_{i=1}^n \n",
    "   \\left[\n",
    "   y_i \\log \\mathbb{P}\\left( Y_i = 1 | X_i = x_i \\right)\n",
    "   + (1-y_i) \\log \\mathbb{P}\\left( Y_i = 0 | X_i = x_i \\right)\n",
    "   \\right]\n",
    "   \\\\\n",
    "   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n",
    "   y_i \\log \\frac{e^{\\beta x_i}}{1+e^{\\beta x_i}}\n",
    "   + (1-y_i) \\log \\frac{1}{1+e^{\\beta x_i}}\n",
    "   \\right]\n",
    "   \\\\\n",
    "   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n",
    "   y_i \\left( \\beta x_i \\right)\n",
    "   + \\log \\frac{1}{1+e^{\\beta x_i}}\n",
    "   \\right]\n",
    "   \\\\\n",
    "   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n",
    "   y_i \\left( \\beta x_i \\right)\n",
    "   - \\log (1+e^{\\beta x_i})\n",
    "   \\right] \\ .\n",
    "   \\\\\n",
    "   & \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad CQFD\n",
    "   \\end{align*}\n",
    "$$\n",
    "- En conséquence:\n",
    "$$\n",
    "   \\nabla_\\beta \\ell\\left( y, x, \\beta \\right)\n",
    " = \\frac{1}{n} \\sum_{i=1}^n \\left(\n",
    "   y_i\n",
    "   -\n",
    "   \\frac{e^{\\beta x_i}}{1+e^{\\beta x_i}}\n",
    "   \\right) x_i\n",
    " = \\frac{1}{n} \\sum_{i=1}^n \\left(\n",
    "   y_i\n",
    "   - \n",
    "   \\frac{1}{1+e^{-\\beta x_i}}\n",
    "   \\right) x_i\n",
    " = \\frac{1}{n} V X \\ ,\n",
    "$$\n",
    "$$\n",
    "   \\nabla_\\beta^2 \\ell\\left( y, x, \\beta \\right)\n",
    " = \\frac{1}{n} \\sum_{i=1}^n \n",
    "   \\frac{-e^{-\\beta x_i}}{(1+e^{-\\beta x_i})^2}\n",
    "   x_i^T x_i \n",
    " = \\frac{1}{n} \\sum_{i=1}^n \n",
    "   \\frac{-1}{2 + e^{-\\beta x_i} + e^{\\beta x_i}}\n",
    "   x_i^T x_i \n",
    " = \\ \\frac{1}{n} X^T W X,\n",
    "$$\n",
    "où $V$ et $W$ sont des matrices explicites\n",
    "\n",
    "\n",
    "Exercice 3:\n",
    "Refaire les calculs ci-dessus et écrire trois fonctions\n",
    "- ${\\it logL}$: Calcul de la log vraisemblance (Fait)\n",
    "- ${\\it diff\\_logL}$ : Calcul de son gradient\n",
    "- ${\\it diff2\\_logL}$: Calcul de la matrice Hessienne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logL( beta, y, x):\n",
    "    result  = 0\n",
    "    betaX   = np.dot(x, beta)\n",
    "    y_betaX = y*betaX\n",
    "    result  = np.sum( y_betaX-np.log(1+np.exp(betaX)) )\n",
    "    result  = result/len(y)\n",
    "    return result\n",
    "\n",
    "\n",
    "def diff_logL( beta, y, x):\n",
    "    result  = 0\n",
    "    # TODO\n",
    "    return result\n",
    "\n",
    "def diff2_logL( beta, y, x):\n",
    "    result = 0\n",
    "    # TODO\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "k     = X.shape[1]\n",
    "beta0 = np.random.rand(k)/100\n",
    "print(\"Log-vraisemblance initiale: \", logL(beta0, Y, X))\n",
    "print(\"Gradient  initial : \", diff_logL(beta0, Y, X))\n",
    "print(\"Hessienne initiale: \", diff2_logL(beta0, Y, X).shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 4:\n",
    "- Ecrire la version vectorielle de Newton-Raphson donnée en cours\n",
    "- Fitter le modèle en maximisant la log vraisemblance par l'algorithme de Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version vectorielle de Newton-Raphson\n",
    "def newton_raphson( x0, func, jacobian_func, n_max=100, eps=1e-8, optional=None):\n",
    "    x = np.zeros(len(x0))\n",
    "    k = 0\n",
    "    # TODO\n",
    "    return (x, k)\n",
    "\n",
    "# Fitting\n",
    "k     = X.shape[1]\n",
    "beta0 = np.zeros(k)\n",
    "l     = lambda beta : logL(beta, Y, X)\n",
    "diff  = lambda beta : diff_logL(beta, Y, X) \n",
    "diff2 = lambda beta : diff2_logL(beta, Y, X) \n",
    "result = newton_raphson( beta0, diff, diff2, optional=l)\n",
    "print(\"\")\n",
    "\n",
    "#Final values\n",
    "print(\" Likelihood: %f \\n Number of iterations: %d \\n Estimated beta:\" % (l(result[0]), result[1]), result[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Comparaison à statmodels\n",
    "\n",
    "Bien entendu, ce que vous venez d'implémenter est standard et est contenu dans les packages python appropriés. \n",
    "\n",
    "Comparez vos résultats à:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "cols=dataframe.columns[:-1]\n",
    "model=sm.Logit(dataframe.risque10ans,dataframe[cols])\n",
    "result=model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
