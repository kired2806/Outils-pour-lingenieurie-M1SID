{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"TP4-Corrige.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bmlMhIqfk8Nc"},"source":["# TP4: Regression logistique (pédestre)\n","\n","Nous nous intéressons au dataset public [Framingham](https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset)\n","issu d'une étude en 1948 à Framingham, Massaschussets, USA et coordonnée par le U.S. Public Health Service. Je vous propose la version [ici](https://www.math.univ-toulouse.fr/~rchhaibi/teaching/2019/M1SID/framingham_fr.csv)\n","où j'ai simplement traduit les champs. Vous pouvez consultez les kernels disponibles, mais le but de ce TP est une implémentation plus manuelle et pédestre de la régression linéaire.\n","\n","Description par le gouvernement américain: [Lien](https://biolincc.nhlbi.nih.gov/studies/framcohort/)\n","- Pour les variables binaires : “1”=“Oui”, “0”=“Non”.\n","- Pour les variables continues: Valeur intensive\n","\n","Variable d'intérêt en dernière colonne:\n","Risque à 10 ans de développer une maladie coronaire (binaire)\n","\n","* Facteurs démographiques:\n","  * Genre: Masculin ou Féminin (binaire: \"1\"=Masculin)\n","  * Age: Continu\n","  * Education: Niveau d'éducation 1,2,3,4\n","* Facteurs comportementaux:\n","  * Fumeur: (binaire)\n","  * CigsParJour: Cigarette par jour\n","* Facteurs médicaux historiques / Historique médical:\n","  * meds (binaire): si le patient est traité pour des problèmes de pression sanguine\n","  * avc  (binaire): si le patient a déjà fait un avc\n","  * hypertension (binaire): si le patient a de l'hypertension\n","  * diabete (binaire): si le patient est diabétique\n","* Facteurs médicaux courants:\n","  * Tot Chol: niveau de cholesterol total HDL + LDL + VLDL (Continu)\n","  * Sys BP: pression sanguine systolique (Continu)\n","  * Dia BP: pression sanguine diastolique (Continu)\n","  * IMC: Indice de Masse Corporelle (Continu)\n","  * freqCardiaque: Fréquence cardiaque (Continu)\n","  * Glucose: niveau de glucose (Continu)"]},{"cell_type":"code","metadata":{"id":"87PmFlfok8Np","executionInfo":{"status":"ok","timestamp":1615304417799,"user_tz":-60,"elapsed":571,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}}},"source":["# Ignore warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Imports\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"usSVIYKtk8Ns"},"source":["## I. Echauffement: L'algorithme de Newton-Raphson\n","\n","Exercice 1:\n","- Implémenter l'algorithme de Newton-Raphson dans sa version scalaire\n","- De même, dans sa version vectorielle\n","- Commenter la vitesse de convergence"]},{"cell_type":"code","metadata":{"id":"WUfkialVk8Nv","executionInfo":{"status":"ok","timestamp":1615304403716,"user_tz":-60,"elapsed":667,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}}},"source":["# Version scalaire\n","def newton_raphson_scalar( x0, func, grad_func, n_max=100, eps=1e-8):\n","    x = x0\n","    x0= x + 2*eps\n","    k = 0\n","    while abs(x-x0)>eps and k<n_max:\n","        x0 = x\n","        x  = x0 - func(x0)/grad_func(x0)\n","        k  = k + 1\n","    return (x, k)\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzO48CUhk8Nw","executionInfo":{"status":"ok","timestamp":1615304420530,"user_tz":-60,"elapsed":562,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"8a643822-324a-405f-efe6-414e84d6b62e"},"source":["# Test pour la version scalaire\n","a    = 2\n","scalar_func = lambda x: x**2-a\n","scalar_grad = lambda x: 2*x\n","\n","count  = 8\n","errors = []\n","print(\"Target value: \", np.sqrt(a))\n","print(\"NR value / Iteration count:\")\n","for n_max in range(1,count):\n","    x, k = newton_raphson_scalar(1, scalar_func, scalar_grad, n_max=n_max)\n","    print(x, k)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Target value:  1.4142135623730951\n","NR value / Iteration count:\n","1.5 1\n","1.4166666666666667 2\n","1.4142156862745099 3\n","1.4142135623746899 4\n","1.4142135623730951 5\n","1.4142135623730951 5\n","1.4142135623730951 5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uC4GXmEtk8N1"},"source":["## II. Exploration de données"]},{"cell_type":"markdown","metadata":{"id":"Bpbbw3fWk8N3"},"source":["Exercice 2:\n","- Lire le code suivant.\n","- Pourquoi enlève-t-on la colonne \"éducation\"? Il s'agit pourant (sans doute) d'un facteur pertinent."]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"jGkciH2ek8N3","executionInfo":{"status":"ok","timestamp":1615304423712,"user_tz":-60,"elapsed":854,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"1c3ba2bf-4b2f-476d-cf67-8a8594c79fbc"},"source":["#Importation des données et nettoyage\n","dataframe=pd.read_csv(\"framingham_fr.csv\")\n","dataframe.drop(['education'],axis=1,inplace=True)\n","dataframe.head()\n","\n","#Counting the missing values and dropping them\n","count=0\n","for i in dataframe.isnull().sum(axis=1):\n","    if i>0:\n","        count=count+1\n","print(\"Le nombre total de lignes avec des valeurs manquantes est \", count)\n","print(\"Il s'agit de\",round((count/len(dataframe.index))*100), '% du jeu de données.')\n","print(\"\")\n","dataframe.dropna(axis=0,inplace=True)\n","\n","#Ajout de la constante\n","from statsmodels.tools import add_constant as add_constant\n","dataframe = add_constant(dataframe)\n","\n","# Statistiques descriptives\n","print(\"Statistiques descriptives:\")\n","dataframe.describe()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Le nombre total de lignes avec des valeurs manquantes est  489\n","Il s'agit de 12 % du jeu de données.\n","\n","Statistiques descriptives:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>const</th>\n","      <th>masculin</th>\n","      <th>age</th>\n","      <th>fumeur</th>\n","      <th>cigsParJour</th>\n","      <th>meds</th>\n","      <th>avc</th>\n","      <th>hypertension</th>\n","      <th>diabete</th>\n","      <th>totChol</th>\n","      <th>sysBP</th>\n","      <th>diaBP</th>\n","      <th>IMC</th>\n","      <th>freqCardiaque</th>\n","      <th>glucose</th>\n","      <th>risque10ans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3749.0</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","      <td>3749.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.0</td>\n","      <td>0.445185</td>\n","      <td>49.578821</td>\n","      <td>0.488397</td>\n","      <td>9.005335</td>\n","      <td>0.030408</td>\n","      <td>0.005601</td>\n","      <td>0.311816</td>\n","      <td>0.027207</td>\n","      <td>236.952787</td>\n","      <td>132.365964</td>\n","      <td>82.933716</td>\n","      <td>25.809651</td>\n","      <td>75.703921</td>\n","      <td>81.883169</td>\n","      <td>0.152574</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.497053</td>\n","      <td>8.569322</td>\n","      <td>0.499932</td>\n","      <td>11.922440</td>\n","      <td>0.171730</td>\n","      <td>0.074643</td>\n","      <td>0.463297</td>\n","      <td>0.162709</td>\n","      <td>44.610417</td>\n","      <td>22.051951</td>\n","      <td>11.933321</td>\n","      <td>4.065894</td>\n","      <td>11.957763</td>\n","      <td>23.888039</td>\n","      <td>0.359624</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>32.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>113.000000</td>\n","      <td>83.500000</td>\n","      <td>48.000000</td>\n","      <td>15.540000</td>\n","      <td>44.000000</td>\n","      <td>40.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>42.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>206.000000</td>\n","      <td>117.000000</td>\n","      <td>75.000000</td>\n","      <td>23.090000</td>\n","      <td>68.000000</td>\n","      <td>71.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>49.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>234.000000</td>\n","      <td>128.000000</td>\n","      <td>82.000000</td>\n","      <td>25.410000</td>\n","      <td>75.000000</td>\n","      <td>78.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>56.000000</td>\n","      <td>1.000000</td>\n","      <td>20.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>264.000000</td>\n","      <td>144.000000</td>\n","      <td>90.000000</td>\n","      <td>28.060000</td>\n","      <td>82.000000</td>\n","      <td>87.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.0</td>\n","      <td>1.000000</td>\n","      <td>70.000000</td>\n","      <td>1.000000</td>\n","      <td>70.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>696.000000</td>\n","      <td>295.000000</td>\n","      <td>142.500000</td>\n","      <td>56.800000</td>\n","      <td>143.000000</td>\n","      <td>394.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        const     masculin  ...      glucose  risque10ans\n","count  3749.0  3749.000000  ...  3749.000000  3749.000000\n","mean      1.0     0.445185  ...    81.883169     0.152574\n","std       0.0     0.497053  ...    23.888039     0.359624\n","min       1.0     0.000000  ...    40.000000     0.000000\n","25%       1.0     0.000000  ...    71.000000     0.000000\n","50%       1.0     0.000000  ...    78.000000     0.000000\n","75%       1.0     1.000000  ...    87.000000     0.000000\n","max       1.0     1.000000  ...   394.000000     1.000000\n","\n","[8 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_l9jb6sk8N5","executionInfo":{"status":"ok","timestamp":1615304581576,"user_tz":-60,"elapsed":640,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"5635a9f2-0b41-4528-e3d5-b8c93d057d3a"},"source":["cols = dataframe.columns\n","# Définition de la variable d'intéret\n","Y = np.array( dataframe[cols[-1]] ) ## risque 10 ans ( var repns)\n","# Définition de la matrice des facteurs\n","X = np.array( dataframe[cols[:-1]] ) ## var exlicatives\n","# Taille des matrices\n","print(\"dim X: \", X.shape)\n","print(\"dim Y: \", Y.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["dim X:  (3749, 15)\n","dim Y:  (3749,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0lRigQ24k8N8"},"source":["## III. Implémentation de la régression logistique\n","\n","Nous nous intéressons à l'estimation de \n","$$ \\mathbb{P}\\left( Y=1 | X \\right)$$\n","grâce à un modèle de régression logistique. On pourra se référer à la [page Wikipedia](https://fr.wikipedia.org/wiki/R%C3%A9gression_logistique#Le_mod%C3%A8le).\n","\n","- La fonction de lien est définie pour $p = \\mathbb{P}\\left( Y = 1 | X \\right) = \\mathbb{E}\\left( Y | X \\right)$ par\n","$$ \n","   \\textrm{logit}( p )\n"," = \\log\\left( \\frac{p}{1-p} \\right)\n"," = \\beta X \\ ,\n","$$\n","où $\\beta X$ est le produit scalaire entre les paramètres $\\beta \\in \\mathbb{R}^k$ et les facteurs $X \\in \\mathbb{R}^k$. De façon équivalente:\n","$$ p = \\frac{e^{\\beta X}}{1+e^{\\beta X}} \\ .$$\n","\n","- Dans ce cas, la log-vraisemblance s'écrit\n","$$\n","   \\ell\\left( y, x, \\beta \\right)\n"," = \\frac{1}{n} \\sum_{i=1}^n \\left[\n","   y_i \\left( \\beta x_i \\right)\n","   - \\log (1+e^{\\beta x_i})\n","   \\right]\n","$$\n","Preuve:\n","$$\n","   \\begin{align*}\n","   \\ell\\left( y, x, \\beta \\right) := & \\frac{1}{n} \\log \\mathbb{P}\\left( \\forall i, \\ Y_i = y_i | \\forall i, \\ X_i = x_i \\right) \\\\\n","   = & \\frac{1}{n} \\sum_{i=1}^n \\log \\mathbb{P}\\left( Y_i = y_i | X_i = x_i \\right) \\\\\n","   = & \\frac{1}{n} \\sum_{i=1}^n \n","   \\left[\n","   y_i \\log \\mathbb{P}\\left( Y_i = 1 | X_i = x_i \\right)\n","   + (1-y_i) \\log \\mathbb{P}\\left( Y_i = 0 | X_i = x_i \\right)\n","   \\right]\n","   \\\\\n","   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n","   y_i \\log \\frac{e^{\\beta x_i}}{1+e^{\\beta x_i}}\n","   + (1-y_i) \\log \\frac{1}{1+e^{\\beta x_i}}\n","   \\right]\n","   \\\\\n","   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n","   y_i \\left( \\beta x_i \\right)\n","   + \\log \\frac{1}{1+e^{\\beta x_i}}\n","   \\right]\n","   \\\\\n","   = & \\frac{1}{n} \\sum_{i=1}^n \\left[\n","   y_i \\left( \\beta x_i \\right)\n","   - \\log (1+e^{\\beta x_i})\n","   \\right] \\ .\n","   \\\\\n","   & \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad CQFD\n","   \\end{align*}\n","$$\n","- En conséquence:\n","$$\n","   \\nabla_\\beta \\ell\\left( y, x, \\beta \\right)\n"," = \\frac{1}{n} \\sum_{i=1}^n \\left(\n","   y_i\n","   -\n","   \\frac{e^{\\beta x_i}}{1+e^{\\beta x_i}}\n","   \\right) x_i\n"," = \\frac{1}{n} \\sum_{i=1}^n \\left(\n","   y_i\n","   - \n","   \\frac{1}{1+e^{-\\beta x_i}}\n","   \\right) x_i\n"," = \\frac{1}{n} V X \\ ,\n","$$\n","$$\n","   \\nabla_\\beta^2 \\ell\\left( y, x, \\beta \\right)\n"," = \\frac{1}{n} \\sum_{i=1}^n \n","   \\frac{-e^{-\\beta x_i}}{(1+e^{-\\beta x_i})^2}\n","   x_i^T x_i \n"," = \\frac{1}{n} \\sum_{i=1}^n \n","   \\frac{-1}{2 + e^{-\\beta x_i} + e^{\\beta x_i}}\n","   x_i^T x_i \n"," = \\ \\frac{1}{n} X^T W X,\n","$$\n","où $V$ et $W$ sont des matrices explicites\n","\n","\n","Exercice 3:\n","Refaire les calculs ci-dessus et écrire trois fonctions\n","- ${\\it logL}$: Calcul de la log vraisemblance (Fait)\n","- ${\\it diff\\_logL}$ : Calcul de son gradient\n","- ${\\it diff2\\_logL}$: Calcul de la matrice Hessienne\n"]},{"cell_type":"code","metadata":{"id":"yJRhfn9-k8N-","executionInfo":{"status":"ok","timestamp":1615305953081,"user_tz":-60,"elapsed":1447,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}}},"source":["def logL( beta, y, x):\n","    result  = 0\n","    betaX   = np.dot(x, beta)\n","    y_betaX = y*betaX\n","    result  = np.sum( y_betaX-np.log(1+np.exp(betaX)) )\n","    result  = result/len(y)\n","    return result\n","\n","\n","def diff_logL( beta, y, x):\n","    result  = 0\n","    betaX   = np.dot(X, beta)\n","    V       = y-1/(1+np.exp(-betaX))\n","    result  = np.dot(V, x)/len(y)\n","    return result\n","\n","def diff2_logL( beta, y, x):\n","    result = 0\n","    betaX  = np.dot(X, beta)\n","    W      = -1/( 2 + np.exp(-betaX) + np.exp( betaX) )\n","    W      = np.diag(W)\n","    result = np.dot( X.transpose(), np.dot(W, X) )\n","    result = result/len(y)\n","    return result\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0zuLR8Qswre","executionInfo":{"status":"ok","timestamp":1615305959079,"user_tz":-60,"elapsed":1564,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"8842121f-2ac2-4ca0-83a5-5b852d7b1493"},"source":["k     = 6\n","beta0 = np.random.rand(k,2)\n","beta0"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.47808369, 0.52129876],\n","       [0.73254411, 0.57087102],\n","       [0.97083817, 0.97280217],\n","       [0.03172322, 0.54715135],\n","       [0.12048875, 0.04148709],\n","       [0.67562802, 0.21317411]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M18gBgerk8OC","executionInfo":{"status":"ok","timestamp":1615305960312,"user_tz":-60,"elapsed":1210,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"ac538b30-fa32-4453-fac2-d937311f78ce"},"source":["# Test\n","k     = X.shape[1]\n","beta0 = np.random.rand(k)\n","print(\"Log-vraisemblance initiale: \", logL(beta0, Y, X))\n","print(\"Gradient  initial : \", diff_logL(beta0, Y, X))\n","print(\"Hessienne initiale: \", diff2_logL(beta0, Y, X).shape )\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Log-vraisemblance initiale:  -inf\n","Gradient  initial :  [-8.47425980e-01 -3.60096026e-01 -4.13014137e+01 -4.09975994e-01\n"," -7.39103761e+00 -2.05388103e-02 -3.46759136e-03 -2.34462523e-01\n"," -1.76046946e-02 -1.99365964e+02 -1.10424780e+02 -6.96400373e+01\n"," -2.17485703e+01 -6.40560149e+01 -6.83243532e+01]\n","Hessienne initiale:  (15, 15)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hb8zE2h0k8OD"},"source":["\n","Exercice 4:\n","- Ecrire la version vectorielle de Newton-Raphson donnée en cours\n","- Fitter le modèle en maximisant la log vraisemblance par l'algorithme de Newton-Raphson"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxbXTNqSyx8r","executionInfo":{"status":"ok","timestamp":1615306919165,"user_tz":-60,"elapsed":617,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"495899c5-ed6a-4271-d6fe-a39a5f330979"},"source":["# Version scalaire\n","def newton_raphson_scalar( x0, func, grad_func, n_max=100, eps=1e-8):\n","    x = x0\n","    x0= x + 2*eps\n","    k = 0\n","    while abs(x-x0)>eps and k<n_max:\n","        x0 = x\n","        x  = x0 - func(x0)/grad_func(x0)\n","        k  = k + 1\n","    return (x, k)\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[2.e-08 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08\n"," 2.e-08 2.e-08 2.e-08 2.e-08 2.e-08]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Wr9zPu5k8OE","executionInfo":{"status":"ok","timestamp":1615307098258,"user_tz":-60,"elapsed":990,"user":{"displayName":"Nour Elhouda Kired","photoUrl":"https://lh3.googleusercontent.com/-t5cKneNsVwY/AAAAAAAAAAI/AAAAAAAAwA4/Ay33FG5EW1s/s64/photo.jpg","userId":"15500978536926819595"}},"outputId":"a752f961-81bc-4975-bd48-9b8f5f503e82"},"source":["# Version vectorielle de Newton-Raphson\n","def newton_raphson( x0, func, jacobian_func, n_max=100, eps=1e-8, optional=None):\n","    x = x0\n","    x0= x + 2*eps\n","    k = 0\n","    while np.max(np.abs(x-x0))>eps and k<n_max:\n","        x0 = x\n","        if optional:\n","            print(\"Step: \", k)\n","            print(\"Likelihood: \", optional(x0))\n","        jacobian     = jacobian_func(x0) ## gradiant d'un vecteur ( matrice k,k)\n","        jacobian_inv = np.linalg.inv(jacobian)\n","        x  = x0 - np.dot(jacobian_inv, func(x0) )\n","        k  = k + 1\n","    return (x, k)\n","\n","# Fitting\n","k     = X.shape[1]\n","beta0 = np.zeros(k)\n","l     = lambda beta : logL(beta, Y, X) ## log-vraisemblance\n","diff  = lambda beta : diff_logL(beta, Y, X) ## gradiant\n","diff2 = lambda beta : diff2_logL(beta, Y, X)   ## hessienne \n","result = newton_raphson( beta0, diff, diff2, optional=l)\n","print(\"\")\n","\n","#Final values\n","print(\" Likelihood: %f \\n Number of iterations: %d \\n Estimated beta:\" % (l(result[0]), result[1]), result[0] )"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Step:  0\n","Likelihood:  -0.6931471805599452\n","Step:  1\n","Likelihood:  -0.3998483688735582\n","Step:  2\n","Likelihood:  -0.3788163731608549\n","Step:  3\n","Likelihood:  -0.3772162644368042\n","Step:  4\n","Likelihood:  -0.37719896260846303\n","Step:  5\n","Likelihood:  -0.37719896004662995\n","Step:  6\n","Likelihood:  -0.37719896004662995\n","\n"," Likelihood: -0.377199 \n"," Number of iterations: 7 \n"," Estimated beta: [-8.64629355e+00  5.73994317e-01  6.40449952e-02  7.31683648e-02\n","  1.83713528e-02  1.44564752e-01  7.19071651e-01  2.14630016e-01\n","  2.47120514e-03  2.24375667e-03  1.53448289e-02 -3.93363611e-03\n","  1.02649003e-02 -2.28503447e-03  7.57614086e-03]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GAlsCRRAwdXh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TL2MrnKik8OE"},"source":["## IV. Comparaison à statmodels\n","\n","Bien entendu, ce que vous venez d'implémenter est standard et est contenu dans les packages python appropriés. \n","\n","Comparez vos résultats à:"]},{"cell_type":"code","metadata":{"id":"NzVdYLQnk8OF","outputId":"9cfbd336-c749-4366-d169-f2bc26cc15a9"},"source":["import statsmodels.api as sm\n","\n","cols=dataframe.columns[:-1]\n","model=sm.Logit(dataframe.risque10ans,dataframe[cols])\n","result=model.fit()\n","result.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Optimization terminated successfully.\n","         Current function value: 0.377199\n","         Iterations 7\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>Logit Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>      <td>risque10ans</td>   <th>  No. Observations:  </th>  <td>  3749</td>  \n","</tr>\n","<tr>\n","  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3734</td>  \n","</tr>\n","<tr>\n","  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    14</td>  \n","</tr>\n","<tr>\n","  <th>Date:</th>            <td>Thu, 27 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1169</td>  \n","</tr>\n","<tr>\n","  <th>Time:</th>                <td>07:14:37</td>     <th>  Log-Likelihood:    </th> <td> -1414.1</td> \n","</tr>\n","<tr>\n","  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1601.4</td> \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.922e-71</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th>         <td>   -8.6463</td> <td>    0.687</td> <td>  -12.577</td> <td> 0.000</td> <td>   -9.994</td> <td>   -7.299</td>\n","</tr>\n","<tr>\n","  <th>masculin</th>      <td>    0.5740</td> <td>    0.107</td> <td>    5.343</td> <td> 0.000</td> <td>    0.363</td> <td>    0.785</td>\n","</tr>\n","<tr>\n","  <th>age</th>           <td>    0.0640</td> <td>    0.007</td> <td>    9.787</td> <td> 0.000</td> <td>    0.051</td> <td>    0.077</td>\n","</tr>\n","<tr>\n","  <th>fumeur</th>        <td>    0.0732</td> <td>    0.155</td> <td>    0.473</td> <td> 0.636</td> <td>   -0.230</td> <td>    0.376</td>\n","</tr>\n","<tr>\n","  <th>cigsParJour</th>   <td>    0.0184</td> <td>    0.006</td> <td>    3.003</td> <td> 0.003</td> <td>    0.006</td> <td>    0.030</td>\n","</tr>\n","<tr>\n","  <th>meds</th>          <td>    0.1446</td> <td>    0.232</td> <td>    0.622</td> <td> 0.534</td> <td>   -0.311</td> <td>    0.600</td>\n","</tr>\n","<tr>\n","  <th>avc</th>           <td>    0.7191</td> <td>    0.489</td> <td>    1.471</td> <td> 0.141</td> <td>   -0.239</td> <td>    1.677</td>\n","</tr>\n","<tr>\n","  <th>hypertension</th>  <td>    0.2146</td> <td>    0.136</td> <td>    1.574</td> <td> 0.116</td> <td>   -0.053</td> <td>    0.482</td>\n","</tr>\n","<tr>\n","  <th>diabete</th>       <td>    0.0025</td> <td>    0.312</td> <td>    0.008</td> <td> 0.994</td> <td>   -0.609</td> <td>    0.614</td>\n","</tr>\n","<tr>\n","  <th>totChol</th>       <td>    0.0022</td> <td>    0.001</td> <td>    2.074</td> <td> 0.038</td> <td>    0.000</td> <td>    0.004</td>\n","</tr>\n","<tr>\n","  <th>sysBP</th>         <td>    0.0153</td> <td>    0.004</td> <td>    4.080</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n","</tr>\n","<tr>\n","  <th>diaBP</th>         <td>   -0.0039</td> <td>    0.006</td> <td>   -0.619</td> <td> 0.536</td> <td>   -0.016</td> <td>    0.009</td>\n","</tr>\n","<tr>\n","  <th>IMC</th>           <td>    0.0103</td> <td>    0.013</td> <td>    0.820</td> <td> 0.412</td> <td>   -0.014</td> <td>    0.035</td>\n","</tr>\n","<tr>\n","  <th>freqCardiaque</th> <td>   -0.0023</td> <td>    0.004</td> <td>   -0.550</td> <td> 0.583</td> <td>   -0.010</td> <td>    0.006</td>\n","</tr>\n","<tr>\n","  <th>glucose</th>       <td>    0.0076</td> <td>    0.002</td> <td>    3.408</td> <td> 0.001</td> <td>    0.003</td> <td>    0.012</td>\n","</tr>\n","</table>"],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                           Logit Regression Results                           \n","==============================================================================\n","Dep. Variable:            risque10ans   No. Observations:                 3749\n","Model:                          Logit   Df Residuals:                     3734\n","Method:                           MLE   Df Model:                           14\n","Date:                Thu, 27 Feb 2020   Pseudo R-squ.:                  0.1169\n","Time:                        07:14:37   Log-Likelihood:                -1414.1\n","converged:                       True   LL-Null:                       -1601.4\n","Covariance Type:            nonrobust   LLR p-value:                 2.922e-71\n","=================================================================================\n","                    coef    std err          z      P>|z|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","const            -8.6463      0.687    -12.577      0.000      -9.994      -7.299\n","masculin          0.5740      0.107      5.343      0.000       0.363       0.785\n","age               0.0640      0.007      9.787      0.000       0.051       0.077\n","fumeur            0.0732      0.155      0.473      0.636      -0.230       0.376\n","cigsParJour       0.0184      0.006      3.003      0.003       0.006       0.030\n","meds              0.1446      0.232      0.622      0.534      -0.311       0.600\n","avc               0.7191      0.489      1.471      0.141      -0.239       1.677\n","hypertension      0.2146      0.136      1.574      0.116      -0.053       0.482\n","diabete           0.0025      0.312      0.008      0.994      -0.609       0.614\n","totChol           0.0022      0.001      2.074      0.038       0.000       0.004\n","sysBP             0.0153      0.004      4.080      0.000       0.008       0.023\n","diaBP            -0.0039      0.006     -0.619      0.536      -0.016       0.009\n","IMC               0.0103      0.013      0.820      0.412      -0.014       0.035\n","freqCardiaque    -0.0023      0.004     -0.550      0.583      -0.010       0.006\n","glucose           0.0076      0.002      3.408      0.001       0.003       0.012\n","=================================================================================\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"P514BipJk8OF"},"source":[""],"execution_count":null,"outputs":[]}]}